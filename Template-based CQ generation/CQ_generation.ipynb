{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_templates(directory=\"templates\"):\n",
    "    \"\"\"\n",
    "    Read all .txt files in the given directory and return a dict\n",
    "    mapping filename (without .txt) to file content.\n",
    "    \"\"\"\n",
    "    templates = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.lower().endswith(\".txt\"):\n",
    "            key = os.path.splitext(filename)[0]\n",
    "            path = os.path.join(directory, filename)\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                templates[key] = f.read()\n",
    "    return templates\n",
    "def init_template(axiom, axiom_relation):\n",
    "    if axiom_relation in [\"domain\", \"range\"]: template = load_templates()[\"domain_range\"]\n",
    "    else: template = load_templates()[axiom_relation]\n",
    "    # Add a hint for the logic of the axiom\n",
    "    logic_hint = \"\"\n",
    "    if any(keyword in axiom for keyword in [\"propertyRestrictions\", \"equivalentClass\"]):\n",
    "        logic_hint = \"\"\"\n",
    "        The axiom may include different logical structures. Determine whether it involves existential/universal restrictions (some/only) or intersection/union (and/or), and generate CQs accordingly.\n",
    "        \"\"\"\n",
    "    elif any(keyword in axiom for keyword in [\"domain\", \"range\"]):\n",
    "        logic_hint = \"\"\"\n",
    "        If the property’s domain or range is undefined (None), generate a Competency Question asking what can be the domain or range of the property, is it right that the property has no domain or range.\n",
    "        \"\"\"\n",
    "    return {\n",
    "        \"custom_id\": None,  \n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4.1\",  \n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"\"\"\n",
    "                    As an ontology engineer, generate a list of competency questions based on the following axiom and one-shot example.\n",
    "                    Definition of competency questions: the questions that outline the scope of ontology and provide an idea about the knowledge that needs to be entailed in the ontology.\n",
    "                    Avoid using narrative questions + axioms.\n",
    "                    Don't generate unnecessary text. Just return 3 distinct CQs separated by ' // '.\n",
    "                    Use the one-shot and known templates only as inspiration — do not copy them directly. Rephrase and vary the structure of each CQ while maintaining its logical intent.\n",
    "                    {logic_hint.strip()}\n",
    "                    \"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"\n",
    "                    Generate a Competency Question including axioms and current template.\n",
    "                    Template: {template}\n",
    "                    Axiom: {axiom}\n",
    "                    \"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Generated CQs:\"\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 512\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35669d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory_path = \"Axiom_per_entity\"\n",
    "ontology_list = {file.split(\"_\")[0]: os.path.join(directory_path, file) for file in os.listdir(directory_path)}\n",
    "print(ontology_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13618013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from copy import deepcopy\n",
    "import random\n",
    "data_num = 0\n",
    "for ontology in ontology_list:\n",
    "    batches = []\n",
    "    seen_ids = set()\n",
    "    with open(ontology_list[ontology], \"r\") as f:\n",
    "        temp_axiom=json.load(f)\n",
    "    for cls in temp_axiom[\"classes\"]:\n",
    "        for axiom_relation in temp_axiom[\"classes\"][cls]:\n",
    "            for axiom_range in temp_axiom[\"classes\"][cls][axiom_relation]:\n",
    "                axiom = f\"{cls} {axiom_relation} {axiom_range}\"\n",
    "                custom_id = f\"{ontology}_{axiom}\"\n",
    "                if custom_id in seen_ids:\n",
    "                    continue\n",
    "                seen_ids.add(custom_id)\n",
    "                temp = deepcopy(init_template(axiom=axiom, axiom_relation=axiom_relation))\n",
    "                temp[\"custom_id\"] = custom_id\n",
    "                batches.append(temp)\n",
    "    for prop in temp_axiom[\"properties\"]:\n",
    "        for axiom_relation in temp_axiom[\"properties\"][prop]:\n",
    "            for axiom_range in temp_axiom[\"properties\"][prop][axiom_relation]:\n",
    "                axiom = f\"{prop} {axiom_relation} {axiom_range}\"\n",
    "                custom_id = f\"{ontology}_{axiom}\"\n",
    "                if custom_id in seen_ids:\n",
    "                    continue\n",
    "                seen_ids.add(custom_id)\n",
    "                temp = deepcopy(init_template(axiom=axiom, axiom_relation=axiom_relation))\n",
    "                temp[\"custom_id\"] = custom_id\n",
    "                batches.append(temp)\n",
    "    # Save the batches to a JSONL file\n",
    "    with open(\"CQ_Batchinput/\"+ontology+'_batchinput.jsonl', 'w', encoding='utf-8') as file:\n",
    "        for item in batches:\n",
    "            json_string = json.dumps(item, ensure_ascii=False)\n",
    "            file.write(json_string + '\\n')\n",
    "        print(f\"Ontology name: {ontology}, Number of batches: {len(batches)}\")\n",
    "    data_num += len(batches)\n",
    "print(f\"Total number of batches: {data_num}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400c19f",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "for ontology in os.listdir(\"CQ_Batchinput\"):\n",
    "  if ontology.endswith(\".jsonl\"):\n",
    "    with open(os.path.join(\"CQ_Batchinput\", ontology), \"rb\") as file:\n",
    "      batch_input_file = client.files.create(\n",
    "        file=file, \n",
    "        purpose=\"batch\"\n",
    "      )\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "\n",
    "# Create a batch job\n",
    "    client.batches.create(\n",
    "      input_file_id=batch_input_file_id,\n",
    "      endpoint=\"/v1/chat/completions\",\n",
    "      completion_window=\"24h\", \n",
    "            )\n",
    "  else:\n",
    "    print(f\"Skipping non-JSONL file: {ontology}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba9b2632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 185 records from 10 JSONL files.\n",
      "Loaded 68 records from 10 JSONL files.\n",
      "Loaded 959 records from 10 JSONL files.\n",
      "Loaded 205 records from 10 JSONL files.\n",
      "Loaded 960 records from 10 JSONL files.\n",
      "Loaded 1105 records from 10 JSONL files.\n",
      "Loaded 64 records from 10 JSONL files.\n",
      "Loaded 128 records from 10 JSONL files.\n",
      "Loaded 194 records from 10 JSONL files.\n",
      "Loaded 332 records from 10 JSONL files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "batchoutput_directory = \"CQ_Batchoutput\"\n",
    "jsonl_files = [file for file in os.listdir(batchoutput_directory) if file.endswith(\".jsonl\")]\n",
    "\n",
    "for jsonl_file in jsonl_files:\n",
    "    loaded_data = []\n",
    "    file_path = os.path.join(batchoutput_directory, jsonl_file)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            temp_data = json.loads(line)\n",
    "            if \"http://\" in temp_data[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]: CQ_list = temp_data[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].split(\"// \")\n",
    "            else: CQ_list = temp_data[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].split(\"//\")\n",
    "            temp_list = []\n",
    "            for CQ in CQ_list:\n",
    "                CQ = CQ.strip()\n",
    "                if CQ == \"\": continue\n",
    "                if CQ[:2]==\"\\n\": CQ = CQ[2:]\n",
    "                if CQ[0]==\"-\": CQ = CQ[1:]\n",
    "                temp_list.append(CQ.strip())\n",
    "            temp_out = {\"axiom\": temp_data[\"custom_id\"].split(\"_\",1)[1], \"CQ\": temp_list}\n",
    "            loaded_data.append(temp_out)\n",
    "    # Save the loaded data to a new jsonl file\n",
    "    output_file_path = os.path.join(\"Generated CQ\", f\"{jsonl_file}\")\n",
    "    with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in loaded_data:\n",
    "            json_string = json.dumps(item, ensure_ascii=False)\n",
    "            f.write(json_string + '\\n')\n",
    "    print(f\"Loaded {len(loaded_data)} records from {len(jsonl_files)} JSONL files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyojun_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
